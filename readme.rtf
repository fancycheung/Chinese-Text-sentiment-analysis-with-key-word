{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset134 PingFangSC-Regular;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Readme\
\
Test in spider python 3.6, Keras 2.2.0.\
Make sure the Keras.backend from Theano, the default is Tensorflow, can be switched manually. (See Keras Document: https://keras.io/backend/)\
\
I tried stopword list from \'93
\f1 \'d6\'d0\'bf\'c6\'d4\'ba\'cd\'a3\'d3\'c3\'b4\'ca\'b1\'ed
\f0 \'94
\f1 \'a3\'ac
\f0  \'94
\f1 \'b9\'fe\'b9\'a4\'b4\'f3\'cd\'a3\'d3\'c3\'b4\'ca\'b1\'ed
\f0 \'93
\f1 \'a3\'ac
\f0  the results do not have better performance than not using. I think these stop words doesn\'92t fit the reviews from online shopping, since the length of reviews is short. Thus, I clear the stopword list at this point, can be added if needed.\
\
\'93Filter pattern\'94 can be customized in first stage.(PreDoc)\
\
\
Toy Example:\
\
Attached includes a pickle file TOYData.pickle prepared with a toy sample, 2000 samples, including clean data, embedding matrix.\
By loading TOYData in \'91A Toy Example.py\'92, clean data, embedding matrix will be ready to process the model built-up, training, and prediction.\
Following are the TOYmodel summary, a simple training process, and prediction with key words result:\
_________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
input_21 (InputLayer)        (None, 6)                 0         \
_________________________________________________________________\
embedding_18 (Embedding)     (None, 6, 300)            809400    \
_________________________________________________________________\
bidirectional_14 (Bidirectio (None, 6, 128)            140160    \
_________________________________________________________________\
attention_19 (Attention)     (None, 128)               134       \
_________________________________________________________________\
dense_10 (Dense)             (None, 2)                 258       \
=================================================================\
Total params: 949,952\
Trainable params: 140,552\
Non-trainable params: 809,400\
_________________________________________________________________\
None\
Train on 1400 samples, validate on 600 samples\
Epoch 1/1\
1400/1400 [==============================] - 474s 339ms/step - loss: 0.6315 - acc: 0.6779 - val_loss: 0.5017 - val_acc: 0.8117\
\
(0 : neg; 1: pos)\
\
   0         1\
0  1      [, ]\
1  1    [
\f1 \'c6\'b7\'c5\'c6
\f0 , ]\
2  0  [
\f1 \'c9\'ab\'b2\'ca
\f0 , 
\f1 \'cf\'ca\'c3\'f7
\f0 ]\
3  0   [
\f1 \'b5\'e7\'b3\'d8
\f0 , 
\f1 \'b2\'bb
\f0 ]\
4  1      [, ]\
5  0  [
\f1 \'d4\'dd\'ca\'b1
\f0 , 
\f1 \'c3\'bb\'d3\'d0
\f0 ]\
6  1  [
\f1 \'b2\'bb\'b4\'ed
\f0 , 
\f1 \'bf\'ec\'bd\'dd
\f0 ]\
7  1   [
\f1 \'ba\'dc
\f0 , 
\f1 \'b2\'bb\'b4\'ed
\f0 ]\
8  0   [
\f1 \'b3\'a4
\f0 , 
\f1 \'bb\'b9\'d2\'aa
\f0 ]\
9  0   [
\f1 \'b8\'d0\'be\'f5
\f0 , 
\f1 \'d4\'aa
\f0 ]\
\
\
\
MYmodel:\
MYData.pickle prepared with all the sample data, corresponding MYmodel trained with 30000 training sample, the training weights has been saved in  MYmodel_weights.h5, can be loaded in the model and continue training.\
The acc rate and val rate of MYmodel achieve around 0.9.\
\
\
\
\
\
\
\
\
}